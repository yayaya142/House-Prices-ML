{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## House Prices - Advanced Regression Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****** HERE WILL BE ID *******"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TL;DR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 Imports and Definitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy, matplotlib, etc. \n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import sweetviz as sw\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn import metrics\n",
    "from sklearn import pipeline\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn import neural_network\n",
    "from sklearn import model_selection\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# define plt settings\n",
    "sns.set_theme()\n",
    "plt.rcParams[\"font.size\"] = 20\n",
    "plt.rcParams[\"axes.labelsize\"] = 20\n",
    "plt.rcParams[\"xtick.labelsize\"] = 20\n",
    "plt.rcParams[\"ytick.labelsize\"] = 20\n",
    "plt.rcParams[\"legend.fontsize\"] = 20\n",
    "plt.rcParams[\"legend.markerscale\"] = 1.5\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 10)\n",
    "plt.rcParams[\"legend.title_fontsize\"] = 20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- define the input and output folders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"input/\"\n",
    "\n",
    "train_data_path = os.path.join(input_folder, \"train.csv\")\n",
    "test_data_path = os.path.join(input_folder, \"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - define the show graphs variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHOW_GRAPHS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the traning data\n",
    "  - Load the csv data to variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(train_data_path)\n",
    "\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "\n",
    "# display the first few rows of the data\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 Data Investigation EDA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove the id column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the \"Id\" column from the train_data DataFrame\n",
    "train_data_id = train_data[\"Id\"]\n",
    "train_data = train_data.drop(\"Id\", axis=1)\n",
    "\n",
    "# Drop the \"Id\" column from the test_data DataFrame\n",
    "test_id = test_data[\"Id\"]\n",
    "test_data = test_data.drop(\"Id\", axis=1)\n",
    "\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Count the number of feuatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of features: {train_data.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get summary statistics for the training dataset show only the numerical columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get the data types of the columns in the training dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that most of the data is object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_missing_data_with_percentage(data):\n",
    "    print(\"Missing values in the dataset:\")\n",
    "    print(\"-----------------------------------------\")\n",
    "    print(\"Total Rows: \", len(data))\n",
    "    print(\"_________________________________________\")\n",
    "    # Display missing values in each column of the training dataset\n",
    "    missing_values = data.isnull().sum()\n",
    "    missing_percentage = (missing_values / len(train_data)) * 100\n",
    "    missing_data = pd.concat([missing_values, missing_percentage], axis=1, keys=['Missing Values', 'Percentage'])\n",
    "    missing_data.sort_values(by='Missing Values', ascending=False, inplace=True)\n",
    "    print(missing_data.head(20))\n",
    "    \n",
    "    print(\"\\n\\nTotal missing values: \", missing_data['Missing Values'].sum())\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display missing values in the training dataset\n",
    "show_missing_data_with_percentage(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the columns \"Alley\", \"PoolQC\", \"Fence\", \"MiscFeature\" have a lot of missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Handle the missing data<br><br>\n",
    "First step to remove highly missing features (by threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_highly_missing_features(data, fetures_to_drop):\n",
    "    data = data.drop(fetures_to_drop, axis=1)\n",
    "    return data\n",
    "\n",
    "\n",
    "def find_features_with_missing_values_threshold(data, threshold):\n",
    "    missing_values = data.isnull().sum()\n",
    "    missing_percentage = (missing_values / len(train_data)) * 100\n",
    "    missing_data = pd.concat([missing_values, missing_percentage], axis=1, keys=['Missing Values', 'Percentage'])\n",
    "    missing_data.sort_values(by='Missing Values', ascending=False, inplace=True)\n",
    "    features_to_drop = missing_data[missing_data['Percentage'] > threshold].index\n",
    "    return features_to_drop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the threshold for missing values to remove\n",
    "threshold = 80\n",
    "# for 80 it return # [\"Alley\", \"PoolQC\", \"Fence\", \"MiscFeature\"]\n",
    "drop_features = find_features_with_missing_values_threshold(train_data, threshold) \n",
    "\n",
    "\n",
    "train_data = drop_highly_missing_features(train_data, drop_features)\n",
    "\n",
    "test_data = drop_highly_missing_features(test_data, drop_features)\n",
    "\n",
    "print(\"Remove this features: \", drop_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_missing_data_with_percentage(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling Missing Values for Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing numerical values with median\n",
    "def handle_missing_values_numerical(data):\n",
    "    for column in data.select_dtypes(include=[np.number]).columns:\n",
    "        data[column].fillna(data[column].median(), inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling Missing Values for Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing categorical values with most frequent value\n",
    "def handle_missing_values_categorical(data):\n",
    "    for column in data.select_dtypes(include=[object]).columns:\n",
    "        data[column].fillna(data[column].mode()[0], inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One function to handle the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(data):\n",
    "    data = handle_missing_values_numerical(data)\n",
    "    data = handle_missing_values_categorical(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the missing values in the train data\n",
    "train_data = handle_missing_values(train_data)\n",
    "\n",
    "# fill the missing values in the test data\n",
    "test_data = handle_missing_values(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify No More Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMissing values in the training dataset after filling:\")\n",
    "print(train_data.isnull().sum().sum())\n",
    "\n",
    "print(\"\\nMissing values in the test dataset after filling:\")\n",
    "print(test_data.isnull().sum().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Categorical Features to Numeric Using One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data types in training data:\")\n",
    "print(train_data.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Analysis & Visualization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_GRAPHS:\n",
    "    plt.figure(figsize=(11, 7))\n",
    "    sns.histplot(train_data['SalePrice'], kde=True, bins=30, color='blue')\n",
    "    plt.title('Distribution of SalePrice')\n",
    "    plt.xlabel('SalePrice')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "if SHOW_GRAPHS:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    stats.probplot(train_data['SalePrice'], dist=\"norm\", plot=plt)\n",
    "    plt.title('Normal Probability Plot of SalePrice')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram for SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_GRAPHS:\n",
    "    fig = px.histogram(train_data, x='SalePrice', title='Distribution of SalePrice')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the distribution of SalePrice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Box plot for SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_GRAPHS:\n",
    "    fig = px.box(train_data, y='SalePrice', title='Boxplot of SalePrice')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OverallQual: Rates the overall material and finish of the house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if SHOW_GRAPHS:\n",
    "    overall_qual_mean = train_data.groupby('OverallQual')['SalePrice'].mean()\n",
    "    fig = px.bar(overall_qual_mean, x=overall_qual_mean.index, y='SalePrice', title='OverallQual vs SalePrice')\n",
    "    fig.add_trace(go.Scatter(x=overall_qual_mean.index, y=overall_qual_mean.values, mode='lines', name='lines'))\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the correlation of each feature with SalePrice and sort them to identify the strongest relationships.\n",
    "- To do so we must encode the categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the data to numerical and categorical columns\n",
    "numerical_columns = train_data.select_dtypes(include=[\"int64\", 'float64']).columns\n",
    "categorical_columns = train_data.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "\n",
    "# Encode the categorical columns\n",
    "categorical_columns_encoded = pd.get_dummies(train_data[categorical_columns])\n",
    "\n",
    "# Combine the numerical and encoded categorical columns\n",
    "train_data_encoded = pd.concat([train_data[numerical_columns], categorical_columns_encoded], axis=1)\n",
    "\n",
    "\n",
    "# Create a correlation matrix\n",
    "correlation_matrix = train_data_encoded.corr().abs()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Change N to the number of top features you want to analyze "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20\n",
    "\n",
    "# Get the top N correlated features with the target variable\n",
    "top_correlated_features = correlation_matrix['SalePrice'].sort_values(ascending=False).head(N).index.tolist()\n",
    "\n",
    "# Filter the correlation matrix to get the top N correlated features\n",
    "filtered_correlation_matrix = correlation_matrix.loc[top_correlated_features, top_correlated_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top correlation with SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Top {N} features with the highest correlation with SalePrice:\")\n",
    "print(filtered_correlation_matrix['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pairplot Visualizing Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_GRAPHS:\n",
    "    sns.pairplot(train_data[top_correlated_features[:5]], height=3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heatmap for correlation matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def show_top_correlated_features(correlation_matrix, n):\n",
    "    # Display the heatmap of the correlation matrix with numbers in each cell\n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=correlation_matrix.values,\n",
    "        x=correlation_matrix.columns,\n",
    "        y=correlation_matrix.columns,\n",
    "        colorscale='Viridis',\n",
    "        text=correlation_matrix.values.round(2),  # Round values for display\n",
    "        texttemplate=\"%{text}\",\n",
    "        showscale=True))\n",
    "    fig.update_layout(title=f\"Top {n} Correlated Features\", width=1000, height=800)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_GRAPHS:\n",
    "    show_top_correlated_features(filtered_correlation_matrix, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Standardization & Outliers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['SalePrice'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardizing data\n",
    "saleprice_scaled = StandardScaler().fit_transform(np.array(train_data['SalePrice']).reshape(-1, 1));\n",
    "low_range = saleprice_scaled[saleprice_scaled[:, 0].argsort()][:10]\n",
    "high_range = saleprice_scaled[saleprice_scaled[:, 0].argsort()][-10:]\n",
    "\n",
    "# Display the low and high range of the SalePrice after standardization\n",
    "print('\\nOuter range (low) of the distribution:')\n",
    "print(low_range)\n",
    "print(\"\\n----------------------------------------\")\n",
    "print('\\nOuter range (high) of the distribution:')\n",
    "print(high_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find and remove outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Function to find the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def show_outliers(data, target, compare):\n",
    "    # Create a scatter plot for data points\n",
    "    fig = go.Figure(data=go.Scatter(\n",
    "        x=data[compare],\n",
    "        y=data[target],\n",
    "        mode='markers',\n",
    "        text=data.index,  # Assuming the index is the ID you want to show on hover\n",
    "        hoverinfo='text+x+y',  # Show ID, x (compare), and y (target) values on hover\n",
    "        marker=dict(color='blue', size=10, line=dict(width=1, color='DarkSlateGrey')),\n",
    "        name='Data Points'\n",
    "    ))\n",
    "    \n",
    "    # Identify outliers (this is an example, adjust according to your criteria)\n",
    "    outliers = data[data[compare] > data[compare].quantile(0.99)]  # Top 1% as outliers\n",
    "    \n",
    "    # Add outliers to the plot with a different color\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=outliers[compare],\n",
    "        y=outliers[target],\n",
    "        mode='markers',\n",
    "        text=outliers.index,  # Assuming the index is the ID you want to show on hover\n",
    "        hoverinfo='text+x+y',  # Show ID, x (compare), and y (target) values on hover\n",
    "        marker=dict(color='red', size=12, line=dict(width=1, color='DarkSlateGrey')),\n",
    "        name='Outliers'\n",
    "    ))\n",
    "    \n",
    "    # Update plot layout\n",
    "    fig.update_layout(title=f'{target} vs {compare}',\n",
    "                      xaxis_title=compare,\n",
    "                      yaxis_title=target,\n",
    "                      hovermode='closest')\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers by index\n",
    "def remove_outliers_by_index(data, index):\n",
    "    try:\n",
    "        if isinstance(index, list):\n",
    "            for i in index:\n",
    "                data = data.drop(i)\n",
    "        else:\n",
    "            data = data.drop(index)\n",
    "    except KeyError:\n",
    "        print(\"Index not found\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GrLivArea: Above grade (ground) living area square feet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the SalePrice vs GrLivArea, and the id of the outliers\n",
    "if SHOW_GRAPHS:\n",
    "    show_outliers(train_data, 'SalePrice', 'GrLivArea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the outliers points\n",
    "index_list = [523, 1298]\n",
    "train_data = remove_outliers_by_index(train_data, index_list)\n",
    "show_outliers(train_data, 'SalePrice', 'GrLivArea')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TotalBsmtSF: Total square feet of basement area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_GRAPHS:\n",
    "    show_outliers(train_data, 'SalePrice', 'TotalBsmtSF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the outliers points\n",
    "index_list = [440, 496, 332]\n",
    "train_data = remove_outliers_by_index(train_data, index_list)\n",
    "\n",
    "show_outliers(train_data, 'SalePrice', 'TotalBsmtSF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram probability plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "\n",
    "def show_probability_plot(data, target):\n",
    "    # Create the Histogram\n",
    "       # Show Histogram with a normal distribution fit line\n",
    "    sns.histplot(train_data[target], kde=True, color=\"blue\", stat=\"density\")\n",
    "    # Overlay the normal distribution fit\n",
    "    mean, std = norm.fit(train_data[target])\n",
    "    xmin, xmax = plt.xlim()\n",
    "    x = np.linspace(xmin, xmax, 100)\n",
    "    p = norm.pdf(x, mean, std)\n",
    "    plt.plot(x, p, 'k', linewidth=2)\n",
    "    title = \"Fit results: mean = %.2f,  std = %.2f\" % (mean, std)\n",
    "    plt.title(title)\n",
    "    \n",
    "    # Normal probability plot\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    stats.probplot(train_data[target], dist=\"norm\", plot=ax)  # Use actual data for the plot\n",
    "    ax.set_title('Normal Probability Plot of {}'.format(target))\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_GRAPHS:\n",
    "    show_probability_plot(train_data, 'SalePrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SalePrice is right skewed, so we need to transform it to be normally distributed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transformation of the target variable\n",
    "train_data['SalePrice'] = np.log(train_data['SalePrice'])\n",
    "\n",
    "if SHOW_GRAPHS:\n",
    "    show_probability_plot(train_data, 'SalePrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will check GrLivArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show histogram and probability plot for GrLivArea\n",
    "if SHOW_GRAPHS:\n",
    "    show_probability_plot(train_data, 'GrLivArea')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GrLivArea is right skewed, so we need to transform it to be normally distributed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transformation of GrLivArea\n",
    "train_data['GrLivArea'] = np.log(train_data['GrLivArea'])\n",
    "\n",
    "if SHOW_GRAPHS:\n",
    "    show_probability_plot(train_data, 'GrLivArea')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total Square Footage\n",
    "- We create a new feature TotalSF by summing up the total basement square footage, first floor square footage, second floor square footage, and garage area. This feature represents the total square footage of the house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_engineering_list = []\n",
    "\n",
    "# create TotalSF feature\n",
    "def create_TotalSF_feature(data, features_engineering_list=None):\n",
    "    data['TotalSqureF'] = data['TotalBsmtSF'] + data['1stFlrSF'] + data['2ndFlrSF'] + data['GarageArea']\n",
    "    if features_engineering_list is not None:\n",
    "        features_engineering_list.append('TotalSqureF')\n",
    "    return data\n",
    "\n",
    "# Create the TotalSF feature for the train and test data\n",
    "train_data = create_TotalSF_feature(train_data, features_engineering_list)\n",
    "\n",
    "test_data = create_TotalSF_feature(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age of the House\n",
    "- We calculate the age of the house at the time of sale by subtracting the year the house was built from the year it was sold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create age_of_house feature\n",
    "def create_age_of_house_feature(data, features_engineering_list=None):\n",
    "    data['AgeOfHouse'] = data['YrSold'] - data['YearBuilt']\n",
    "    if features_engineering_list is not None:\n",
    "        features_engineering_list.append('AgeOfHouse')\n",
    "    return data\n",
    "\n",
    "\n",
    "# Create the AgeOfHouse feature for the train and test data\n",
    "train_data = create_age_of_house_feature(train_data, features_engineering_list)\n",
    "\n",
    "test_data = create_age_of_house_feature(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age of the Renovation\n",
    "- We calculate the age of the house since its most recent renovation by subtracting the year of the most recent renovation from the year it was sold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create age_of_renovation feature\n",
    "def create_age_of_renovation_feature(data, features_engineering_list=None):\n",
    "    data['AgeOfRenovation'] = data['YrSold'] - data['YearRemodAdd']\n",
    "    if features_engineering_list is not None:\n",
    "        features_engineering_list.append('AgeOfRenovation')\n",
    "    return data\n",
    "\n",
    "# Create the AgeOfRenovation feature for the train and test data\n",
    "train_data = create_age_of_renovation_feature(train_data, features_engineering_list)\n",
    "\n",
    "test_data = create_age_of_renovation_feature(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total Bathrooms\n",
    "- We create a new feature TotalBath by summing up the number of full and half bathrooms in the basement and above grade, with half bathrooms counted as 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create TotalBath feature\n",
    "def create_TotalBath_feature(data, features_engineering_list=None):\n",
    "    data['TotalBath'] = data['FullBath'] + 0.5 * data['HalfBath'] + data['BsmtFullBath'] + 0.5 * data['BsmtHalfBath']\n",
    "    if features_engineering_list is not None:\n",
    "        features_engineering_list.append('TotalBath')\n",
    "    return data\n",
    "\n",
    "# Create the TotalBath feature for the train and test data\n",
    "train_data = create_TotalBath_feature(train_data, features_engineering_list)\n",
    "\n",
    "test_data = create_TotalBath_feature(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total Porch Area\n",
    "- We create a new feature TotalPorchSF by summing up the area of all porch-related features, representing the total porch area of the house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create TotalPorchSF feature\n",
    "def create_TotalPorchSF_feature(data, features_engineering_list=None):\n",
    "    data['TotalPorchSF'] = data['OpenPorchSF'] + data['EnclosedPorch'] + data['3SsnPorch'] + data['ScreenPorch']\n",
    "    if features_engineering_list is not None:\n",
    "        features_engineering_list.append('TotalPorchSF')\n",
    "    return data\n",
    "\n",
    "# Create the TotalPorchSF feature for the train and test data\n",
    "train_data = create_TotalPorchSF_feature(train_data, features_engineering_list)\n",
    "\n",
    "test_data = create_TotalPorchSF_feature(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data[features_engineering_list].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_GRAPHS:\n",
    "    # Split the data to numerical and categorical columns\n",
    "    numerical_columns = train_data.select_dtypes(include=[\"int64\", 'float64']).columns\n",
    "    categorical_columns = train_data.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "\n",
    "    # Encode the categorical columns\n",
    "    categorical_columns_encoded = pd.get_dummies(train_data[categorical_columns])\n",
    "\n",
    "    # Combine the numerical and encoded categorical columns\n",
    "    train_data_encoded = pd.concat([train_data[numerical_columns], categorical_columns_encoded], axis=1)\n",
    "\n",
    "\n",
    "    # Create a correlation matrix\n",
    "    correlation_matrix = train_data_encoded.corr().abs()\n",
    "    \n",
    "    # Get the top N correlated features with the target variable\n",
    "    top_correlated_features = correlation_matrix['SalePrice'].sort_values(ascending=False).head(N).index.tolist()\n",
    "\n",
    "    # Filter the correlation matrix to get the top N correlated features\n",
    "    filtered_correlation_matrix = correlation_matrix.loc[top_correlated_features, top_correlated_features]\n",
    "    \n",
    "    show_top_correlated_features(filtered_correlation_matrix, N)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 Regression Models & Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre model Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split the data into features and target variable (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into features and target variable\n",
    "X = train_data.drop(['SalePrice'], axis=1)\n",
    "y = train_data['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "X = pd.get_dummies(X)\n",
    "X_test = pd.get_dummies(test_data)\n",
    "\n",
    "# Align the columns in the test set to match the train set\n",
    "X, X_test = X.align(X_test, join='left', axis=1, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define a function for computing RMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "def rmse_cv(model):\n",
    "    rmse = np.sqrt(-cross_val_score(model, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=5))\n",
    "    return rmse.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implementing different regression models<br> evaluating them using Cross Validation, and computing the RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Pipelines for Each Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "lin_reg_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lin_reg', LinearRegression())\n",
    "])\n",
    "\n",
    "lin_reg_rmse = rmse_cv(lin_reg_pipeline)\n",
    "print(f\"Linear Regression RMSE: {lin_reg_rmse}\")\n",
    "\n",
    "# Fit the model and predict\n",
    "lin_reg_pipeline.fit(X_train, y_train)\n",
    "y_pred = lin_reg_pipeline.predict(X_val)\n",
    "lin_reg_val_rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "print(f\"Linear Regression Validation RMSE: {lin_reg_val_rmse}\")\n",
    "lin_reg_pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SGD Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD Regressor\n",
    "sgd_reg_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('sgd_reg', SGDRegressor(max_iter=1000, tol=1e-3, random_state=42))\n",
    "])\n",
    "\n",
    "sgd_reg_rmse = rmse_cv(sgd_reg_pipeline)\n",
    "print(f\"SGD Regressor RMSE: {sgd_reg_rmse}\")\n",
    "\n",
    "# Fit the model and predict\n",
    "sgd_reg_pipeline.fit(X_train, y_train)\n",
    "y_pred = sgd_reg_pipeline.predict(X_val)\n",
    "sgd_reg_val_rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "print(f\"SGD Regressor Validation RMSE: {sgd_reg_val_rmse}\")\n",
    "sgd_reg_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "ridge_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('ridge', Ridge())\n",
    "])\n",
    "\n",
    "# Define the hyperparameters grid\n",
    "ridge_param_grid = {\n",
    "    'ridge__alpha': [0.1, 1.0, 10.0, 100.0]\n",
    "}\n",
    "\n",
    "ridge_grid_search = GridSearchCV(ridge_pipeline, ridge_param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "ridge_grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_ridge = ridge_grid_search.best_estimator_\n",
    "best_ridge_rmse = np.sqrt(-ridge_grid_search.best_score_)\n",
    "print(f\"Best Ridge model: {best_ridge}\")\n",
    "print(f\"Best Ridge RMSE: {best_ridge_rmse}\")\n",
    "\n",
    "# Fit the best model and predict\n",
    "best_ridge.fit(X_train, y_train)\n",
    "y_pred = best_ridge.predict(X_val)\n",
    "ridge_reg_val_rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "print(f\"Ridge Regression Validation RMSE: {ridge_reg_val_rmse}\")\n",
    "ridge_pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso Regression\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "\n",
    "lasso_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lasso', Lasso())\n",
    "])\n",
    "\n",
    "lasso_param_grid = {\n",
    "    'lasso__alpha': [0.01, 0.1, 1.0, 10.0],\n",
    "    'lasso__max_iter': [1000, 5000, 10000]\n",
    "}\n",
    "\n",
    "lasso_grid_search = GridSearchCV(lasso_pipeline, lasso_param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "lasso_grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_lasso = lasso_grid_search.best_estimator_\n",
    "best_lasso_rmse = np.sqrt(-lasso_grid_search.best_score_)\n",
    "print(f\"Best Lasso model: {best_lasso}\")\n",
    "print(f\"Best Lasso RMSE: {best_lasso_rmse}\")\n",
    "\n",
    "# Fit the best model and predict\n",
    "best_lasso.fit(X_train, y_train)\n",
    "y_pred = best_lasso.predict(X_val)\n",
    "lasso_reg_val_rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "print(f\"Lasso Regression Validation RMSE: {lasso_reg_val_rmse}\")\n",
    "lasso_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Elastic Net Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elastic Net Regression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "\n",
    "elastic_net_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('elastic_net', ElasticNet())\n",
    "])\n",
    "\n",
    "elastic_net_param_grid = {\n",
    "    'elastic_net__alpha': [0.01, 0.1, 1.0],\n",
    "    'elastic_net__l1_ratio': [0.1, 0.5, 0.9],\n",
    "    'elastic_net__max_iter': [1000, 5000, 10000]\n",
    "}\n",
    "\n",
    "elastic_net_grid_search = GridSearchCV(elastic_net_pipeline, elastic_net_param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "elastic_net_grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_elastic_net = elastic_net_grid_search.best_estimator_\n",
    "best_elastic_net_rmse = np.sqrt(-elastic_net_grid_search.best_score_)\n",
    "print(f\"Best Elastic Net model: {best_elastic_net}\")\n",
    "print(f\"Best Elastic Net RMSE: {best_elastic_net_rmse}\")\n",
    "\n",
    "# Fit the best model and predict\n",
    "best_elastic_net.fit(X_train, y_train)\n",
    "y_pred = best_elastic_net.predict(X_val)\n",
    "elastic_net_val_rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "print(f\"Elastic Net Regression Validation RMSE: {elastic_net_val_rmse}\")\n",
    "elastic_net_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display bar plot for the best 3 models\n",
    "if SHOW_GRAPHS:\n",
    "    fig = go.Figure(data=[\n",
    "        go.Bar(name='Ridge', x=['Ridge'], y=[best_ridge_rmse], text=[best_ridge_rmse], textposition='auto'),\n",
    "        go.Bar(name='Lasso', x=['Lasso'], y=[best_lasso_rmse], text=[best_lasso_rmse], textposition='auto'),\n",
    "        go.Bar(name='Elastic Net', x=['Elastic Net'], y=[best_elastic_net_rmse], text=[best_elastic_net_rmse], textposition='auto')\n",
    "    ])\n",
    "    \n",
    "    fig.update_layout(title='Best RMSE for Ridge, Lasso, and Elastic Net',\n",
    "                      xaxis_title='Model',\n",
    "                      yaxis_title='RMSE')\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recursive Feature Elimination (RFE) for All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to perform RFE\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "def rfe_feature_selection(model, num_features):\n",
    "    rfe = RFE(model, n_features_to_select=num_features)\n",
    "    rfe.fit(X_train, y_train)\n",
    "    selected_features = [feature for feature, selected in zip(X.columns, rfe.support_) if selected]\n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Perform RFE with Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # \n",
    "# selected_features = rfe_feature_selection(LinearRegression(), 20)\n",
    "# print(f\"Selected features: {selected_features}\")\n",
    "\n",
    "# # Re-train Linear Regression with selected features\n",
    "# X_train_selected = X_train[selected_features]\n",
    "# X_val_selected = X_val[selected_features]\n",
    "# X_test_selected = X_test[selected_features]\n",
    "\n",
    "# # Pipeline with selected features\n",
    "# selected_features_pipeline = Pipeline([\n",
    "#     ('scaler', StandardScaler()),\n",
    "#     ('lin_reg', LinearRegression())\n",
    "# ])\n",
    "\n",
    "# selected_features_pipeline.fit(X_train_selected, y_train)\n",
    "# y_pred = selected_features_pipeline.predict(X_val_selected)\n",
    "# selected_features_rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "# print(f\"Linear Regression with Selected Features RMSE: {selected_features_rmse}\")\n",
    "# selected_features_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare Model Performance After RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Ridge Regression': best_ridge,\n",
    "    'Lasso Regression': best_lasso,\n",
    "    'Elastic Net Regression': best_elastic_net\n",
    "}\n",
    "\n",
    "# Fit models and calculate validation RMSE\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    results[name] = rmse\n",
    "    print(f\"{name} Validation RMSE: {rmse}\")\n",
    "    \n",
    "    \n",
    "\n",
    "# set the best model name\n",
    "best_model_name = min(results, key=results.get)\n",
    "print(\"-----------------------------\")\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(f\"Validation RMSE: {results[best_model_name]}\")\n",
    "best_model = models[best_model_name]\n",
    "    \n",
    "# Plot model performance\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.bar(results.keys(), results.values())\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Model Comparison')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4 Export Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Run the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create sumbission file for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({'Id': test_id, 'SalePrice': predictions})\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "\n",
    "# print the time of the submission\n",
    "time = pd.Timestamp.now()\n",
    "formatted_time = time.strftime('%H:%M:%S')\n",
    "print(f\"Your submission was successfully saved at time {formatted_time}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DELETE IN THE END!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load real result and submission\n",
    "real_result = pd.read_csv(\"compare/RESULT_FROM_WEB_REMOVE.csv\")\n",
    "submission_test = pd.read_csv('submission.csv')\n",
    "\n",
    "# Merge DataFrames on 'Id' column\n",
    "merged_df = pd.merge(submission_test, real_result, on='Id', suffixes=('_pred', '_real'))\n",
    "\n",
    "# Calculate RMSE based on logarithm of values\n",
    "rmse = np.sqrt(mean_squared_error(np.log(merged_df['SalePrice_real']), np.log(merged_df['SalePrice_pred'])))\n",
    "\n",
    "print(f\"Root Mean Squared Error (RMSE) between submission and real result (log scale): {rmse:.4f}\")\n",
    "\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot histogram for real_result\n",
    "plt.hist(real_result['SalePrice'], bins=30, alpha=0.5, label='Real Result', color='blue')\n",
    "\n",
    "# Plot histogram for submission_df\n",
    "plt.hist(submission_test['SalePrice'], bins=30, alpha=0.5, label='Submission', color='green')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.title('Distribution of Sale Prices')\n",
    "plt.xlabel('Sale Price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "house-prices_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
